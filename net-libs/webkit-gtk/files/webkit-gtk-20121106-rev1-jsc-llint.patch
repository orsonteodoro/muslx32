source: https://bug-101325-attachments.webkit.org/attachment.cgi?id=172528&action=diff&format=raw&headers=1
submitter: Yuqiang Xian
bug report: https://bugs.webkit.org/show_bug.cgi?id=101325

--- Source/JavaScriptCore/ChangeLog	(revision 133571)
+++ Source/JavaScriptCore/ChangeLog	(working copy)
@@ -1,3 +1,24 @@ 
+2012-11-06  Yuqiang Xian  <yuqiang.xian@intel.com>
+
+        x32 backend of the LLInt
+        https://bugs.webkit.org/show_bug.cgi?id=101325
+
+        Reviewed by NOBODY (OOPS!).
+
+        The basic shape.
+
+        * llint/LLIntData.cpp:
+        (JSC::LLInt::Data::performAssertions):
+        * llint/LLIntOfflineAsmConfig.h:
+        * llint/LLIntSlowPaths.h:
+        (SlowPathReturnType):
+        (JSC::LLInt::encodeResult):
+        (JSC::LLInt::decodeResult):
+        * llint/LowLevelInterpreter.asm:
+        * llint/LowLevelInterpreter64.asm:
+        * offlineasm/backends.rb:
+        * offlineasm/x86.rb:
+
 2012-11-05  Filip Pizlo  <fpizlo@apple.com>
 
         DFG should not fall down to patchable GetById just because a prototype had things added to it
--- Source/JavaScriptCore/llint/LLIntData.cpp	(revision 133560)
+++ Source/JavaScriptCore/llint/LLIntData.cpp	(working copy)
@@ -107,7 +107,7 @@ void Data::performAssertions(JSGlobalDat
     ASSERT(MasqueradesAsUndefined == 1);
     ASSERT(ImplementsHasInstance == 2);
     ASSERT(ImplementsDefaultHasInstance == 8);
-#if USE(JSVALUE64)
+#if USE(JSVALUE64) && !CPU(X32)
     ASSERT(&globalData.heap.allocatorForObjectWithoutDestructor(JSObject::allocationSize(INLINE_STORAGE_CAPACITY)) - &globalData.heap.firstAllocatorWithoutDestructors() == 1);
 #else
     ASSERT(&globalData.heap.allocatorForObjectWithoutDestructor(JSObject::allocationSize(INLINE_STORAGE_CAPACITY)) - &globalData.heap.firstAllocatorWithoutDestructors() == 3);
--- Source/JavaScriptCore/llint/LLIntOfflineAsmConfig.h	(revision 133560)
+++ Source/JavaScriptCore/llint/LLIntOfflineAsmConfig.h	(working copy)
@@ -37,6 +37,7 @@ 
 #define OFFLINE_ASM_X86 0
 #define OFFLINE_ASM_ARMv7 0
 #define OFFLINE_ASM_X86_64 0
+#define OFFLINE_ASM_X32 0
 #define OFFLINE_ASM_ARMv7s 0
 
 #else // !ENABLE(LLINT_C_LOOP)
@@ -61,7 +62,13 @@ 
 #define OFFLINE_ASM_ARMv7 0
 #endif
 
-#if CPU(X86_64)
+#if CPU(X86_64) && CPU(X32)
+#define OFFLINE_ASM_X32 1
+#else
+#define OFFLINE_ASM_X32 0
+#endif
+
+#if CPU(X86_64) && !CPU(X32)
 #define OFFLINE_ASM_X86_64 1
 #else
 #define OFFLINE_ASM_X86_64 0
--- Source/JavaScriptCore/llint/LLIntSlowPaths.h	(revision 133560)
+++ Source/JavaScriptCore/llint/LLIntSlowPaths.h	(working copy)
@@ -43,22 +43,22 @@ namespace LLInt {
 // 'extern "C"') needs to be POD; hence putting any constructors into it could cause either compiler
 // warnings, or worse, a change in the ABI used to return these types.
 struct SlowPathReturnType {
-    void* a;
-    ExecState* b;
+    int64_t a;
+    int64_t b;
 };
 
 inline SlowPathReturnType encodeResult(void* a, ExecState* b)
 {
     SlowPathReturnType result;
-    result.a = a;
-    result.b = b;
+    result.a = reinterpret_cast<uintptr_t>(a);
+    result.b = reinterpret_cast<uintptr_t>(b);
     return result;
 }
 
 inline void decodeResult(SlowPathReturnType result, void*& a, ExecState*& b)
 {
-    a = result.a;
-    b = result.b;
+    a = reinterpret_cast<void*>(result.a);
+    b = reinterpret_cast<ExecState*>(result.b);
 }
 
 #else // USE(JSVALUE32_64)
--- Source/JavaScriptCore/llint/LowLevelInterpreter64.asm	(revision 133560)
+++ Source/JavaScriptCore/llint/LowLevelInterpreter64.asm	(working copy)
@@ -34,7 +34,11 @@ const ValueNull       = TagBitTypeOther
 
 # Utilities.
 macro jumpToInstruction()
-    jmp [PB, PC, 8]
+    if X32
+        jmp [PB, PC, 4]
+    else
+        jmp [PB, PC, 8]
+    end
 end
 
 macro dispatch(advance)
@@ -48,7 +52,11 @@ macro dispatchInt(advance)
 end
 
 macro dispatchIntIndirect(offset)
-    dispatchInt(offset * 8[PB, PC, 8])
+    if X32
+        dispatchInt(offset * 4[PB, PC, 4])
+    else
+        dispatchInt(offset * 8[PB, PC, 8])
+    end
 end
 
 macro dispatchAfterCall()
@@ -59,7 +67,7 @@ macro dispatchAfterCall()
 end
 
 macro cCall2(function, arg1, arg2)
-    if X86_64
+    if X86_64 or X32
         move arg1, t5
         move arg2, t4
         call function
@@ -72,7 +80,7 @@ end
 
 # This barely works. arg3 and arg4 should probably be immediates.
 macro cCall4(function, arg1, arg2, arg3, arg4)
-    if X86_64
+    if X86_64 or X32
         move arg1, t5
         move arg2, t4
         move arg3, t1
@@ -86,7 +94,11 @@ macro cCall4(function, arg1, arg2, arg3,
 end
 
 macro prepareStateForCCall()
-    leap [PB, PC, 8], PC
+    if X32
+        leap [PB, PC, 4], PC
+    else
+        leap [PB, PC, 8], PC
+    end
     move PB, t3
 end
 
@@ -95,7 +107,11 @@ macro restoreStateAfterCCall()
     move t1, cfr
     move t3, PB
     subp PB, PC
-    rshiftp 3, PC
+    if X32
+        rshiftp 2, PC
+    else
+        rshiftp 3, PC
+    end
 end
 
 macro callSlowPath(slowPath)
@@ -1244,7 +1260,11 @@ _llint_op_jneq_ptr:
     loadisFromInstruction(2, t1)
     loadp CodeBlock[cfr], t2
     loadp CodeBlock::m_globalObject[t2], t2
-    loadp JSGlobalObject::m_specialPointers[t2, t1, 8], t1
+    if X32
+        loadp JSGlobalObject::m_specialPointers[t2, t1, 4], t1
+    else
+        loadp JSGlobalObject::m_specialPointers[t2, t1, 8], t1
+    end
     bpneq t1, [cfr, t0, 8], .opJneqPtrTarget
     dispatch(4)
 
@@ -1534,7 +1554,11 @@ _llint_op_catch:
     loadp JITStackFrame::globalData[sp], t3
     loadp JSGlobalData::targetInterpreterPCForThrow[t3], PC
     subp PB, PC
-    rshiftp 3, PC
+    if X32
+        rshiftp 2, PC
+    else
+        rshiftp 3, PC
+    end
     loadq JSGlobalData::exception[t3], t0
     storeq 0, JSGlobalData::exception[t3]
     loadisFromInstruction(1, t2)
@@ -1570,7 +1594,7 @@ _llint_throw_during_call_trampoline:
 
 macro nativeCallTrampoline(executableOffsetToFunction)
     storep 0, CodeBlock[cfr]
-    if X86_64
+    if X86_64 or X32
         loadp JITStackFrame::globalData + 8[sp], t0
         storep cfr, JSGlobalData::topCallFrame[t0]
         loadp CallerFrame[cfr], t0
--- Source/JavaScriptCore/llint/LowLevelInterpreter.asm	(revision 133560)
+++ Source/JavaScriptCore/llint/LowLevelInterpreter.asm	(working copy)
@@ -55,16 +55,30 @@ if JSVALUE64
     const tagTypeNumber = csr1
     const tagMask = csr2
     
-    macro loadisFromInstruction(offset, dest)
-        loadis offset * 8[PB, PC, 8], dest
-    end
+    if X32
+        macro loadisFromInstruction(offset, dest)
+            loadis offset * 4[PB, PC, 4], dest
+        end
     
-    macro loadpFromInstruction(offset, dest)
-        loadp offset * 8[PB, PC, 8], dest
-    end
+        macro loadpFromInstruction(offset, dest)
+            loadp offset * 4[PB, PC, 4], dest
+        end
+    
+        macro storepToInstruction(value, offset)
+            storep value, offset * 4[PB, PC, 4]
+        end
+    else
+        macro loadisFromInstruction(offset, dest)
+            loadis offset * 8[PB, PC, 8], dest
+        end
     
-    macro storepToInstruction(value, offset)
-        storep value, offset * 8[PB, PC, 8]
+        macro loadpFromInstruction(offset, dest)
+            loadp offset * 8[PB, PC, 8], dest
+        end
+    
+        macro storepToInstruction(value, offset)
+            storep value, offset * 8[PB, PC, 8]
+        end
     end
 
 else
@@ -145,7 +159,11 @@ const PutToBaseOperationKindVariablePut
 
 # Allocation constants
 if JSVALUE64
-    const JSFinalObjectSizeClassIndex = 1
+    if X32
+        const JSFinalObjectSizeClassIndex = 3
+    else
+        const JSFinalObjectSizeClassIndex = 1
+    end
 else
     const JSFinalObjectSizeClassIndex = 3
 end
@@ -153,7 +171,11 @@ end
 # This must match wtf/Vector.h
 const VectorSizeOffset = 0
 if JSVALUE64
-    const VectorBufferOffset = 8
+    if X32
+        const VectorBufferOffset = 4
+    else
+        const VectorBufferOffset = 8
+    end
 else
     const VectorBufferOffset = 4
 end
@@ -184,7 +206,7 @@ macro preserveReturnAddressAfterCall(des
         move lr, destinationRegister
     elsif ARMv7
         move lr, destinationRegister
-    elsif X86 or X86_64
+    elsif X86 or X86_64 or X32
         pop destinationRegister
     else
         error
@@ -197,7 +219,7 @@ macro restoreReturnAddressBeforeReturn(s
         move sourceRegister, lr
     elsif ARMv7
         move sourceRegister, lr
-    elsif X86 or X86_64
+    elsif X86 or X86_64 or X32
         push sourceRegister
     else
         error
--- Source/JavaScriptCore/offlineasm/backends.rb	(revision 133560)
+++ Source/JavaScriptCore/offlineasm/backends.rb	(working copy)
@@ -31,6 +31,7 @@ BACKENDS =
     [
      "X86",
      "X86_64",
+     "X32",
      "ARMv7",
      "C_LOOP"
     ]
@@ -44,6 +45,7 @@ WORKING_BACKENDS =
     [
      "X86",
      "X86_64",
+     "X32",
      "ARMv7",
      "C_LOOP"
     ]
--- Source/JavaScriptCore/offlineasm/x86.rb	(revision 133560)
+++ Source/JavaScriptCore/offlineasm/x86.rb	(working copy)
@@ -29,6 +29,21 @@ def isX64
         false
     when "X86_64"
         true
+    when "X32"
+        true # X32 is a special mode of X86_64
+    else
+        raise "bad value for $activeBackend: #{$activeBackend}"
+    end
+end
+
+def isX32
+    case $activeBackend
+    when "X86"
+        false
+    when "X86_64"
+        false
+    when "X32"
+        true
     else
         raise "bad value for $activeBackend: #{$activeBackend}"
     end
@@ -44,7 +59,7 @@ class SpecialRegister < NoChildren
         when :int
             "%" + @name + "d"
         when :ptr
-            "%" + @name
+            isX32 ? "%" + @name + "d" : "%" + @name
         when :quad
             "%" + @name
         else
@@ -55,6 +70,9 @@ class SpecialRegister < NoChildren
         # Call operands are not allowed to be partial registers.
         "*#{x86Operand(:quad)}"
     end
+    def x86PushOperand(kind)
+       "#{x86Operand(:quad)}"
+    end
 end
 
 X64_SCRATCH_REGISTER = SpecialRegister.new("r11")
@@ -84,7 +102,7 @@ class RegisterID
             when :int
                 "%eax"
             when :ptr
-                isX64 ? "%rax" : "%eax"
+                isX64 && !isX32 ? "%rax" : "%eax"
             when :quad
                 isX64 ? "%rax" : raise
             else
@@ -99,7 +117,7 @@ class RegisterID
             when :int
                 "%edx"
             when :ptr
-                isX64 ? "%rdx" : "%edx"
+                isX64 && !isX32 ? "%rdx" : "%edx"
             when :quad
                 isX64 ? "%rdx" : raise
             else
@@ -114,7 +132,7 @@ class RegisterID
             when :int
                 "%ecx"
             when :ptr
-                isX64 ? "%rcx" : "%ecx"
+                isX64 && !isX32 ? "%rcx" : "%ecx"
             when :quad
                 isX64 ? "%rcx" : raise
             else
@@ -129,7 +147,7 @@ class RegisterID
             when :int
                 "%ebx"
             when :ptr
-                isX64 ? "%rbx" : "%ebx"
+                isX64 && !isX32 ? "%rbx" : "%ebx"
             when :quad
                 isX64 ? "%rbx" : raise
             else
@@ -144,7 +162,7 @@ class RegisterID
             when :int
                 "%esi"
             when :ptr
-                isX64 ? "%rsi" : "%esi"
+                isX64 && !isX32 ? "%rsi" : "%esi"
             when :quad
                 isX64 ? "%rsi" : raise
             else
@@ -158,7 +176,7 @@ class RegisterID
                 when :int
                     "%r13d"
                 when :ptr
-                    "%r13"
+                    isX32 ? "%r13d" : "%r13"
                 when :quad
                     "%r13"
                 else
@@ -187,7 +205,7 @@ class RegisterID
             when :int
                 "%esp"
             when :ptr
-                isX64 ? "%rsp" : "%esp"
+                isX64 && !isX32 ? "%rsp" : "%esp"
             when :quad
                 isX64 ? "%rsp" : raise
             else
@@ -203,7 +221,7 @@ class RegisterID
             when :int
                 "%edi"
             when :ptr
-                "%rdi"
+                isX32 ? "%edi" : "%rdi"
             when :quad
                 "%rdi"
             end
@@ -215,7 +233,7 @@ class RegisterID
             when :int
                 "%r10d"
             when :ptr
-                "%r10"
+                isX32 ? "%r10d" : "%r10"
             when :quad
                 "%r10"
             end
@@ -227,7 +245,7 @@ class RegisterID
             when :int
                 "%r14d"
             when :ptr
-                "%r14"
+                isX32 ? "%r14d" : "%r14"
             when :quad
                 "%r14"
             end
@@ -239,7 +257,7 @@ class RegisterID
             when :int
                 "%r15d"
             when :ptr
-                "%r15"
+                isX32 ? "%r15d" : "%r15"
             when :quad
                 "%r15"
             end
@@ -250,6 +268,9 @@ class RegisterID
     def x86CallOperand(kind)
         isX64 ? "*#{x86Operand(:quad)}" : "*#{x86Operand(:ptr)}"
     end
+    def x86PushOperand(kind)
+        isX64 ? "#{x86Operand(:quad)}" : "#{x86Operand(:ptr)}"
+    end
 end
 
 class FPRegisterID
@@ -275,6 +296,9 @@ class FPRegisterID
     def x86CallOperand(kind)
         "*#{x86Operand(kind)}"
     end
+    def x86PushOperand(kind)
+        "#{x86Operand(kind)}"
+    end
 end
 
 class Immediate
@@ -291,6 +315,9 @@ class Immediate
     def x86CallOperand(kind)
         "#{value}"
     end
+    def x86PushOperand(kind)
+        "$#{value}"
+    end
 end
 
 class Address
@@ -307,6 +334,9 @@ class Address
     def x86CallOperand(kind)
         "*#{x86Operand(kind)}"
     end
+    def x86PushOperand(kind)
+        "#{x86Operand(kind)}"
+    end
 end
 
 class BaseIndex
@@ -325,6 +355,10 @@ class BaseIndex
     def x86CallOperand(kind)
         "*#{x86Operand(kind)}"
     end
+
+    def x86PushOperand(kind)
+        "#{x86Operand(kind)}"
+    end
 end
 
 class AbsoluteAddress
@@ -343,6 +377,10 @@ class AbsoluteAddress
     def x86CallOperand(kind)
         "*#{address.value}"
     end
+    
+    def x86PushOperand(kind)
+        "#{address.value}"
+    end
 end
 
 class LabelReference
@@ -396,6 +434,9 @@ class Sequence
         
         return newList
     end
+    def getModifiedListX32
+        return getModifiedListX86_64
+    end
 end
 
 class Instruction
@@ -418,7 +459,7 @@ class Instruction
         when :int
             "l"
         when :ptr
-            isX64 ? "q" : "l"
+            isX64 && !isX32 ? "q" : "l"
         when :quad
             isX64 ? "q" : raise
         when :double
@@ -437,7 +478,7 @@ class Instruction
         when :int
             4
         when :ptr
-            isX64 ? 8 : 4
+            isX64 && !isX32 ? 8 : 4
         when :quad
             isX64 ? 8 : raise
         when :double
@@ -466,6 +507,19 @@ class Instruction
         handleX86OpWithNumOperands(opcode, kind, operands.size)
     end
     
+    def handleX86Jump(opcode, kind)
+        if isX32
+            if operands[0].is_a? Address or operands[0].is_a? BaseIndex or operands[0].is_a? AbsoluteAddress
+                $asm.puts "mov#{x86Suffix(kind)} #{operands[0].x86Operand(kind)}, #{X64_SCRATCH_REGISTER.x86Operand(kind)}"
+                $asm.puts "#{opcode} #{X64_SCRATCH_REGISTER.x86CallOperand(kind)}"
+            else
+                $asm.puts "#{opcode} #{operands[0].x86CallOperand(kind)}"
+            end
+        else
+            $asm.puts "#{opcode} #{operands[0].x86CallOperand(kind)}"
+        end
+    end
+
     def handleX86Shift(opcode, kind)
         if operands[0].is_a? Immediate or operands[0] == RegisterID.forName(nil, "t2")
             $asm.puts "#{opcode} #{operands[0].x86Operand(:byte)}, #{operands[1].x86Operand(kind)}"
@@ -660,6 +714,11 @@ class Instruction
         lowerX86Common
     end
     
+    def lowerX32
+        raise unless $activeBackend == "X32"
+        lowerX86Common
+    end
+
     def lowerX86Common
         $asm.codeOrigin codeOriginString if $enableCodeOriginComments
         $asm.annotation annotation if $enableInstrAnnotations
@@ -815,9 +874,9 @@ class Instruction
         when "movdz"
             $asm.puts "xorpd #{operands[0].x86Operand(:double)}, #{operands[0].x86Operand(:double)}"
         when "pop"
-            $asm.puts "pop #{operands[0].x86Operand(:ptr)}"
+            $asm.puts "pop #{operands[0].x86PushOperand(:ptr)}"
         when "push"
-            $asm.puts "push #{operands[0].x86Operand(:ptr)}"
+            $asm.puts "push #{operands[0].x86PushOperand(:ptr)}"
         when "move"
             handleMove
         when "sxi2q"
@@ -931,7 +990,8 @@ class Instruction
         when "btbnz"
             handleX86BranchTest("jnz", :byte)
         when "jmp"
-            $asm.puts "jmp #{operands[0].x86CallOperand(:ptr)}"
+            # $asm.puts "jmp #{operands[0].x86CallOperand(:ptr)}"
+            handleX86Jump("jmp", :ptr)
         when "baddio"
             handleX86OpBranch("addl", "jo", :int)
         when "baddpo"
@@ -983,7 +1043,8 @@ class Instruction
         when "break"
             $asm.puts "int $3"
         when "call"
-            $asm.puts "call #{operands[0].x86CallOperand(:ptr)}"
+            # $asm.puts "call #{operands[0].x86CallOperand(:ptr)}"
+            handleX86Jump("call", :ptr)
         when "ret"
             $asm.puts "ret"
         when "cieq"

