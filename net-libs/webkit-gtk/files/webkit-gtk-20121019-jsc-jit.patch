source: https://bug-99153-attachments.webkit.org/attachment.cgi?id=169623&action=diff&format=raw&headers=1
submitter: Yuqiang Xian
bug report: https://bugs.webkit.org/show_bug.cgi?id=99153
--

--- Source/JavaScriptCore/assembler/AbstractMacroAssembler.h	(revision 131870)
+++ Source/JavaScriptCore/assembler/AbstractMacroAssembler.h	(working copy)
@@ -229,7 +229,7 @@ public:
         {
         }
 
-#if !CPU(X86_64)
+#if !CPU(X86_64) || CPU(X32)
         explicit TrustedImm32(TrustedImmPtr ptr)
             : m_value(ptr.asIntptr())
         {
@@ -251,7 +251,7 @@ public:
             : TrustedImm32(value)
         {
         }
-#if !CPU(X86_64)
+#if !CPU(X86_64) || CPU(X32)
         explicit Imm32(TrustedImmPtr ptr)
             : TrustedImm32(ptr)
         {
@@ -275,7 +275,7 @@ public:
         {
         }
 
-#if CPU(X86_64)
+#if CPU(X86_64) && !CPU(X32)
         explicit TrustedImm64(TrustedImmPtr ptr)
             : m_value(ptr.asIntptr())
         {
@@ -296,7 +296,7 @@ public:
             : TrustedImm64(value)
         {
         }
-#if CPU(X86_64)
+#if CPU(X86_64) && !CPU(X32)
         explicit Imm64(TrustedImmPtr ptr)
             : TrustedImm64(ptr)
         {
--- Source/JavaScriptCore/assembler/MacroAssembler.h	(revision 131870)
+++ Source/JavaScriptCore/assembler/MacroAssembler.h	(working copy)
@@ -311,7 +311,7 @@ public:
     // Ptr methods
     // On 32-bit platforms (i.e. x86), these methods directly map onto their 32-bit equivalents.
     // FIXME: should this use a test for 32-bitness instead of this specific exception?
-#if !CPU(X86_64)
+#if !CPU(X86_64) || CPU(X32)
     void addPtr(Address src, RegisterID dest)
     {
         add32(src, dest);
@@ -433,16 +433,16 @@ public:
         return load32WithCompactAddressOffsetPatch(address, dest);
     }
 
-    void move(ImmPtr imm, RegisterID dest)
+    void comparePtr(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID dest)
     {
-        move(Imm32(imm.asTrustedImmPtr()), dest);
+        compare32(cond, left, right, dest);
     }
 
-    void comparePtr(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID dest)
+    void comparePtr(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
     {
         compare32(cond, left, right, dest);
     }
-
+    
     void storePtr(RegisterID src, ImplicitAddress address)
     {
         store32(src, address);
@@ -463,11 +463,6 @@ public:
         store32(TrustedImm32(imm), address);
     }
     
-    void storePtr(ImmPtr imm, Address address)
-    {
-        store32(Imm32(imm.asTrustedImmPtr()), address);
-    }
-
     void storePtr(TrustedImmPtr imm, void* address)
     {
         store32(TrustedImm32(imm), address);
@@ -487,11 +482,6 @@ public:
     {
         return branch32(cond, left, TrustedImm32(right));
     }
-    
-    Jump branchPtr(RelationalCondition cond, RegisterID left, ImmPtr right)
-    {
-        return branch32(cond, left, Imm32(right.asTrustedImmPtr()));
-    }
 
     Jump branchPtr(RelationalCondition cond, RegisterID left, Address right)
     {
@@ -557,6 +547,28 @@ public:
     {
         return MacroAssemblerBase::branchTest8(cond, Address(address.base, address.offset), mask);
     }
+
+#if !CPU(X32)
+    void move(ImmPtr imm, RegisterID dest)
+    {
+        move(Imm32(imm.asTrustedImmPtr()), dest);
+    }
+
+    void storePtr(ImmPtr imm, Address address)
+    {
+        store32(Imm32(imm.asTrustedImmPtr()), address);
+    }
+
+    Jump branchPtr(RelationalCondition cond, RegisterID left, ImmPtr right)
+    {
+        return branch32(cond, left, Imm32(right.asTrustedImmPtr()));
+    }
+#else
+    void rotateRightPtr(TrustedImm32 imm, RegisterID srcDst)
+    {
+        rotateRight32(imm, srcDst);
+    }
+#endif
 #else
     void addPtr(RegisterID src, RegisterID dest)
     {
@@ -832,6 +844,9 @@ public:
     {
         return branchSub64(cond, src1, src2, dest);
     }
+#endif // !CPU(X86_64) || CPU(X32)
+
+#if CPU(X86_64)
 
 #if ENABLE(JIT_CONSTANT_BLINDING)
     using MacroAssemblerBase::and64;
@@ -877,10 +892,12 @@ public:
         case 0xffff:
         case 0xffffff:
         case 0xffffffffL:
+#if !CPU(X32)
         case 0xffffffffffL:
         case 0xffffffffffffL:
         case 0xffffffffffffffL:
         case 0xffffffffffffffffL:
+#endif
             return false;
         default: {
             if (value <= 0xff)
@@ -1043,7 +1060,7 @@ public:
 
 #endif
 
-#endif // !CPU(X86_64)
+#endif // CPU(X86_64)
 
 #if ENABLE(JIT_CONSTANT_BLINDING)
     bool shouldBlind(Imm32 imm)
--- Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h	(revision 131870)
+++ Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h	(working copy)
@@ -959,7 +959,12 @@ public:
 
     void push(Address address)
     {
+#if CPU(X32)
+        m_assembler.movq_mr(address.offset, address.base, scratchRegister);
+        m_assembler.push_r(scratchRegister);
+#else
         m_assembler.push_m(address.offset, address.base);
+#endif
     }
 
     void push(TrustedImm32 imm)
@@ -993,7 +998,11 @@ public:
 
     void move(TrustedImmPtr imm, RegisterID dest)
     {
+#if CPU(X32)
+        m_assembler.movl_i32r(imm.asIntptr(), dest);
+#else
         m_assembler.movq_i64r(imm.asIntptr(), dest);
+#endif
     }
 
     void move(TrustedImm64 imm, RegisterID dest)
@@ -1192,7 +1201,12 @@ public:
     // Address is a memory location containing the address to jump to
     void jump(Address address)
     {
+#if CPU(X32)
+        load32(address, scratchRegister);
+        m_assembler.jmp_r(scratchRegister);
+#else
         m_assembler.jmp_m(address.offset, address.base);
+#endif
     }
 
 
@@ -1359,7 +1373,12 @@ public:
 
     void call(Address address)
     {
+#if CPU(X32)
+        load32(address, scratchRegister);
+        m_assembler.call(scratchRegister);
+#else
         m_assembler.call_m(address.offset, address.base);
+#endif
     }
 
     void ret()
--- Source/JavaScriptCore/assembler/MacroAssemblerX86_64.h	(revision 131870)
+++ Source/JavaScriptCore/assembler/MacroAssemblerX86_64.h	(working copy)
@@ -36,10 +36,15 @@ namespace JSC {
 
 class MacroAssemblerX86_64 : public MacroAssemblerX86Common {
 public:
+#if CPU(X32)
+    static const Scale ScalePtr = TimesFour;
+#else
     static const Scale ScalePtr = TimesEight;
+#endif
 
     using MacroAssemblerX86Common::add32;
     using MacroAssemblerX86Common::and32;
+    using MacroAssemblerX86Common::branch32;
     using MacroAssemblerX86Common::branchAdd32;
     using MacroAssemblerX86Common::or32;
     using MacroAssemblerX86Common::sub32;
@@ -110,12 +115,39 @@ public:
         m_assembler.cvtsi2sd_rr(scratchRegister, dest);
     }
 
+    void rotateRight32(TrustedImm32 imm, RegisterID srcDst)
+    {
+        m_assembler.rorl_i8r(imm.m_value, srcDst);
+    }
+
     void store32(TrustedImm32 imm, void* address)
     {
         move(TrustedImmPtr(address), scratchRegister);
         store32(imm, scratchRegister);
     }
     
+    void store32(RegisterID src, void* address)
+    {
+        if (src == X86Registers::eax)
+            m_assembler.movl_EAXm(address);
+        else {
+            move(TrustedImmPtr(address), scratchRegister);
+            store32(src, scratchRegister);
+        }
+    }
+    
+    Jump branch32(RelationalCondition cond, AbsoluteAddress left, RegisterID right)
+    {
+        move(TrustedImmPtr(left.m_ptr), scratchRegister);
+        return branch32(cond, Address(scratchRegister), right);
+    }
+
+    Jump branch32(RelationalCondition cond, AbsoluteAddress left, TrustedImm32 right)
+    {
+        move(TrustedImmPtr(left.m_ptr), scratchRegister);
+        return branch32(cond, left, right);
+    }
+
     void store8(TrustedImm32 imm, void* address)
     {
         move(TrustedImmPtr(address), scratchRegister);
@@ -528,33 +560,53 @@ public:
     ConvertibleLoadLabel convertibleLoadPtr(Address address, RegisterID dest)
     {
         ConvertibleLoadLabel result = ConvertibleLoadLabel(this);
+#if CPU(X32)
+        m_assembler.movl_mr(address.offset, address.base, dest);
+#else
         m_assembler.movq_mr(address.offset, address.base, dest);
+#endif
         return result;
     }
 
     DataLabelPtr moveWithPatch(TrustedImmPtr initialValue, RegisterID dest)
     {
         padBeforePatch();
+#if CPU(X32)
+        m_assembler.movl_i32r(initialValue.asIntptr(), dest);
+#else
         m_assembler.movq_i64r(initialValue.asIntptr(), dest);
+#endif
         return DataLabelPtr(this);
     }
 
     Jump branchPtrWithPatch(RelationalCondition cond, RegisterID left, DataLabelPtr& dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(0))
     {
         dataLabel = moveWithPatch(initialRightValue, scratchRegister);
+#if CPU(X32)
+        return branch32(cond, left, scratchRegister);
+#else
         return branch64(cond, left, scratchRegister);
+#endif
     }
 
     Jump branchPtrWithPatch(RelationalCondition cond, Address left, DataLabelPtr& dataLabel, TrustedImmPtr initialRightValue = TrustedImmPtr(0))
     {
         dataLabel = moveWithPatch(initialRightValue, scratchRegister);
+#if CPU(X32)
+        return branch32(cond, left, scratchRegister);
+#else
         return branch64(cond, left, scratchRegister);
+#endif
     }
 
     DataLabelPtr storePtrWithPatch(TrustedImmPtr initialValue, ImplicitAddress address)
     {
         DataLabelPtr label = moveWithPatch(initialValue, scratchRegister);
+#if CPU(X32)
+        store32(scratchRegister, address);
+#else
         store64(scratchRegister, address);
+#endif
         return label;
     }
     
--- Source/JavaScriptCore/assembler/X86Assembler.h	(revision 131870)
+++ Source/JavaScriptCore/assembler/X86Assembler.h	(working copy)
@@ -683,6 +683,16 @@ public:
         }
     }
 
+    void rorl_i8r(int imm, RegisterID dst)
+    {
+        if (imm == 1)
+            m_formatter.oneByteOp(OP_GROUP2_Ev1, GROUP2_OP_ROR, dst);
+        else {
+            m_formatter.oneByteOp(OP_GROUP2_EvIb, GROUP2_OP_ROR, dst);
+            m_formatter.immediate8(imm);
+        }
+    }
+
 #endif
 
     void sarl_i8r(int imm, RegisterID dst)
@@ -1007,6 +1017,11 @@ public:
         m_formatter.oneByteOp64(OP_TEST_EvGv, src, base, offset);
     }
 
+    void testl_rm(RegisterID src, int offset, RegisterID base)
+    {
+        m_formatter.oneByteOp(OP_TEST_EvGv, src, base, offset);
+    }
+
     void testq_i32r(int imm, RegisterID dst)
     {
         m_formatter.oneByteOp64(OP_GROUP3_EvIz, GROUP3_OP_TEST, dst);
@@ -1111,7 +1126,7 @@ public:
     {
         m_formatter.oneByteOp(OP_MOV_EAXOv);
 #if CPU(X86_64)
-        m_formatter.immediate64(reinterpret_cast<int64_t>(addr));
+        m_formatter.immediate64(reinterpret_cast<uintptr_t>(addr));
 #else
         m_formatter.immediate32(reinterpret_cast<int>(addr));
 #endif
@@ -1193,7 +1208,7 @@ public:
     {
         m_formatter.oneByteOp(OP_MOV_OvEAX);
 #if CPU(X86_64)
-        m_formatter.immediate64(reinterpret_cast<int64_t>(addr));
+        m_formatter.immediate64(reinterpret_cast<uintptr_t>(addr));
 #else
         m_formatter.immediate32(reinterpret_cast<int>(addr));
 #endif
@@ -1223,13 +1238,13 @@ public:
     void movq_mEAX(const void* addr)
     {
         m_formatter.oneByteOp64(OP_MOV_EAXOv);
-        m_formatter.immediate64(reinterpret_cast<int64_t>(addr));
+        m_formatter.immediate64(reinterpret_cast<uintptr_t>(addr));
     }
 
     void movq_EAXm(const void* addr)
     {
         m_formatter.oneByteOp64(OP_MOV_OvEAX);
-        m_formatter.immediate64(reinterpret_cast<int64_t>(addr));
+        m_formatter.immediate64(reinterpret_cast<uintptr_t>(addr));
     }
 
     void movq_mr(int offset, RegisterID base, RegisterID dst)
--- Source/JavaScriptCore/dfg/DFGNode.h	(revision 131870)
+++ Source/JavaScriptCore/dfg/DFGNode.h	(working copy)
@@ -65,7 +65,7 @@ struct StructureTransitionData {
 struct OpInfo {
     explicit OpInfo(int32_t value) : m_value(static_cast<uintptr_t>(value)) { }
     explicit OpInfo(uint32_t value) : m_value(static_cast<uintptr_t>(value)) { }
-#if OS(DARWIN) || USE(JSVALUE64)
+#if !CPU(X32) && (OS(DARWIN) || USE(JSVALUE64))
     explicit OpInfo(size_t value) : m_value(static_cast<uintptr_t>(value)) { }
 #endif
     explicit OpInfo(void* value) : m_value(reinterpret_cast<uintptr_t>(value)) { }
--- Source/JavaScriptCore/dfg/DFGOperations.cpp	(revision 131870)
+++ Source/JavaScriptCore/dfg/DFGOperations.cpp	(working copy)
@@ -1462,6 +1462,7 @@ namespace JSC {
 
 #if COMPILER(GCC) && CPU(X86_64)
 asm (
+".text" "\n" \
 ".globl " SYMBOL_STRING(getHostCallReturnValue) "\n"
 HIDE_SYMBOL(getHostCallReturnValue) "\n"
 SYMBOL_STRING(getHostCallReturnValue) ":" "\n"
--- Source/JavaScriptCore/dfg/DFGSpeculativeJIT64.cpp	(revision 131870)
+++ Source/JavaScriptCore/dfg/DFGSpeculativeJIT64.cpp	(working copy)
@@ -1033,6 +1033,9 @@ void SpeculativeJIT::emitCall(Node& node
     m_jit.addPtr(TrustedImm32(m_jit.codeBlock()->m_numCalleeRegisters * sizeof(Register)), GPRInfo::callFrameRegister);
     
     slowPath.append(m_jit.branchPtrWithPatch(MacroAssembler::NotEqual, calleeGPR, targetToCheck, MacroAssembler::TrustedImmPtr(0)));
+#if CPU(X32)
+    slowPath.append(m_jit.branchTest64(MacroAssembler::NonZero, calleeGPR, GPRInfo::tagMaskRegister));
+#endif
 
     m_jit.loadPtr(MacroAssembler::Address(calleeGPR, OBJECT_OFFSETOF(JSFunction, m_scope)), resultGPR);
     m_jit.store64(resultGPR, MacroAssembler::Address(GPRInfo::callFrameRegister, static_cast<ptrdiff_t>(sizeof(Register)) * JSStack::ScopeChain));
--- Source/JavaScriptCore/jit/ExecutableAllocator.h	(revision 131870)
+++ Source/JavaScriptCore/jit/ExecutableAllocator.h	(working copy)
@@ -106,7 +106,7 @@ class DemandExecutableAllocator;
 #if ENABLE(EXECUTABLE_ALLOCATOR_FIXED)
 #if CPU(ARM)
 static const size_t fixedExecutableMemoryPoolSize = 16 * 1024 * 1024;
-#elif CPU(X86_64)
+#elif CPU(X86_64) && !CPU(X32)
 static const size_t fixedExecutableMemoryPoolSize = 1024 * 1024 * 1024;
 #else
 static const size_t fixedExecutableMemoryPoolSize = 32 * 1024 * 1024;
--- Source/JavaScriptCore/jit/JITCall.cpp	(revision 131870)
+++ Source/JavaScriptCore/jit/JITCall.cpp	(working copy)
@@ -194,6 +194,11 @@ void JIT::compileOpCall(OpcodeID opcodeI
     END_UNINTERRUPTED_SEQUENCE(sequenceOpCall);
     addSlowCase(slowCase);
 
+#if CPU(X32)
+    // The above branchPtr doesn't catch the case where the callee isn't a cell.
+    addSlowCase(branchTest64(NonZero, regT0, tagMaskRegister));
+#endif
+
     ASSERT(m_callStructureStubCompilationInfo.size() == callLinkInfoIndex);
     m_callStructureStubCompilationInfo.append(StructureStubCompilationInfo());
     m_callStructureStubCompilationInfo[callLinkInfoIndex].hotPathBegin = addressOfLinkedFunctionCheck;
@@ -215,6 +220,9 @@ void JIT::compileOpCallSlowCase(OpcodeID
     }
 
     linkSlowCase(iter);
+#if CPU(X32)
+    linkSlowCase(iter);
+#endif
     
     m_callStructureStubCompilationInfo[callLinkInfoIndex].callReturnLocation = emitNakedCall(opcodeID == op_construct ? m_globalData->jitStubs->ctiVirtualConstructLink() : m_globalData->jitStubs->ctiVirtualCallLink());
 
--- Source/JavaScriptCore/jit/JITStubs.cpp	(revision 131870)
+++ Source/JavaScriptCore/jit/JITStubs.cpp	(working copy)
@@ -366,6 +366,7 @@ SYMBOL_STRING(ctiOpThrowNotCaught) ":" "
 
 #if COMPILER(GCC) && CPU(X86_64)
 
+#if !CPU(X32)
 // These ASSERTs remind you that, if you change the layout of JITStackFrame, you
 // need to change the assembly trampolines below to match.
 COMPILE_ASSERT(offsetof(struct JITStackFrame, callFrame) == 0x58, JITStackFrame_callFrame_offset_matches_ctiTrampoline);
@@ -432,6 +433,72 @@ SYMBOL_STRING(ctiOpThrowNotCaught) ":" "
     "popq %rbp" "\n"
     "ret" "\n"
 );
+#else
+// ASSERT(offsetof(struct JITStackFrame, callFrame) == 0x48);
+// ASSERT(offsetof(struct JITStackFrame, code) == 0x40);
+// ASSERT(offsetof(struct JITStackFrame, savedRBX) == 0x58);
+
+asm (
+".text\n"
+".globl " SYMBOL_STRING(ctiTrampoline) "\n"
+HIDE_SYMBOL(ctiTrampoline) "\n"
+SYMBOL_STRING(ctiTrampoline) ":" "\n"
+    "pushq %rbp" "\n"
+    "movl %esp, %ebp" "\n"
+    "pushq %r12" "\n"
+    "pushq %r13" "\n"
+    "pushq %r14" "\n"
+    "pushq %r15" "\n"
+    "pushq %rbx" "\n"
+    // Form the JIT stubs area
+    "subl $0x58, %esp" "\n"
+    "movl %r9d, 0x54(%esp)" "\n"
+    "movl %r8d, 0x50(%esp)" "\n"
+    "movl %ecx, 0x4c(%esp)" "\n"
+    "movl %edx, 0x48(%esp)" "\n"
+    "movl %esi, 0x44(%esp)" "\n"
+    "movl %edi, 0x40(%esp)" "\n"
+    "movq $512, %r12" "\n"
+    "movq $0xFFFF000000000000, %r14" "\n"
+    "movq $0xFFFF000000000002, %r15" "\n"
+    "movl %edx, %r13d" "\n"
+    "call *%rdi" "\n"
+    "addl $0x58, %esp" "\n"
+    "popq %rbx" "\n"
+    "popq %r15" "\n"
+    "popq %r14" "\n"
+    "popq %r13" "\n"
+    "popq %r12" "\n"
+    "popq %rbp" "\n"
+    "ret" "\n"
+".globl " SYMBOL_STRING(ctiTrampolineEnd) "\n"
+HIDE_SYMBOL(ctiTrampolineEnd) "\n"
+SYMBOL_STRING(ctiTrampolineEnd) ":" "\n"
+);
+
+asm (
+".globl " SYMBOL_STRING(ctiVMThrowTrampoline) "\n"
+HIDE_SYMBOL(ctiVMThrowTrampoline) "\n"
+SYMBOL_STRING(ctiVMThrowTrampoline) ":" "\n"
+    "movl %esp, %edi" "\n"
+    "call " LOCAL_REFERENCE(cti_vm_throw) "\n"
+    "int3" "\n"
+);
+
+asm (
+".globl " SYMBOL_STRING(ctiOpThrowNotCaught) "\n"
+HIDE_SYMBOL(ctiOpThrowNotCaught) "\n"
+SYMBOL_STRING(ctiOpThrowNotCaught) ":" "\n"
+    "addl $0x58, %esp" "\n"
+    "popq %rbx" "\n"
+    "popq %r15" "\n"
+    "popq %r14" "\n"
+    "popq %r13" "\n"
+    "popq %r12" "\n"
+    "popq %rbp" "\n"
+    "ret" "\n"
+);
+#endif
 
 #else
     #error "JIT not supported on this platform."
--- Source/JavaScriptCore/jit/JITStubs.h	(revision 131870)
+++ Source/JavaScriptCore/jit/JITStubs.h	(working copy)
@@ -99,9 +99,9 @@ namespace JSC {
 
 #if CPU(X86_64)
     struct JITStackFrame {
-        void* reserved; // Unused
+        int64_t reserved; // Unused
         JITStubArg args[6];
-        void* padding[2]; // Maintain 32-byte stack alignment (possibly overkill).
+        void* padding[2]; // Maintain 32-byte stack alignment (possibly overkill). FIXME: The comments are not valid!
 
         void* code;
         JSStack* stack;
@@ -110,16 +110,21 @@ namespace JSC {
         void* unused2;
         JSGlobalData* globalData;
 
-        void* savedRBX;
-        void* savedR15;
-        void* savedR14;
-        void* savedR13;
-        void* savedR12;
-        void* savedRBP;
-        void* savedRIP;
+        int64_t savedRBX;
+        int64_t savedR15;
+        int64_t savedR14;
+        int64_t savedR13;
+        int64_t savedR12;
+        int64_t savedRBP;
+        int64_t savedRIP;
 
         // When JIT code makes a call, it pushes its return address just below the rest of the stack.
+#if CPU(X32)
+        // On X32 the return address occupies a 8-byte slot (with the higher 4 bytes zero'ed)
+        ReturnAddressPtr* returnAddressSlot() { return reinterpret_cast<ReturnAddressPtr*>(this) - 2; }
+#else
         ReturnAddressPtr* returnAddressSlot() { return reinterpret_cast<ReturnAddressPtr*>(this) - 1; }
+#endif
     };
 #elif CPU(X86)
 #if COMPILER(MSVC) || (OS(WINDOWS) && COMPILER(GCC))
--- Source/JavaScriptCore/runtime/MatchResult.h	(revision 131870)
+++ Source/JavaScriptCore/runtime/MatchResult.h	(working copy)
@@ -64,8 +64,13 @@ struct MatchResult {
         return start == end;
     }
 
+#if CPU(X32)
+    uint64_t start;
+    uint64_t end;
+#else
     size_t start;
     size_t end;
+#endif
 };
 
 #endif
--- Source/WTF/wtf/Platform.h	(revision 131870)
+++ Source/WTF/wtf/Platform.h	(working copy)
@@ -160,6 +160,9 @@ 
 #if   defined(__x86_64__) \
     || defined(_M_X64)
 #define WTF_CPU_X86_64 1
+#if defined(__ILP32__)
+#define WTF_CPU_X32 1
+#endif
 #endif
 
 /* CPU(ARM) - ARM, any version*/

